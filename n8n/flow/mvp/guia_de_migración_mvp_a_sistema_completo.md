# üöÄ Gu√≠a de Migraci√≥n: MVP a Sistema Completo

## üìã Tabla de Contenidos

1.  [Visi√≥n General](#visi√≥n-general)
2.  [Arquitectura Comparativa](#arquitectura-comparativa)
3.  [Funcionalidades y Migraci√≥n](#funcionalidades-y-migraci√≥n)
4.  [Proceso de Migraci√≥n](#proceso-de-migraci√≥n)
5.  [Validaci√≥n y Testing](#validaci√≥n-y-testing)
6.  [Rollback Strategy](#rollback-strategy)
7.  [M√©tricas de √âxito](#m√©tricas-de-√©xito)
8.  [Contactos de Emergencia](#contactos-de-emergencia)
9.  [Scripts de Migraci√≥n](#scripts-de-migraci√≥n-mvp-a-sistema-completo)

## üéØ Visi√≥n General

Esta gu√≠a documenta el proceso de migraci√≥n desde el MVP de WhatsApp Commerce hasta el sistema completo con todas las optimizaciones y funcionalidades avanzadas.

### Objetivos de la Migraci√≥n

-   ‚úÖ Mantener el servicio operativo durante la migraci√≥n
-   ‚úÖ Migrar funcionalidades de forma incremental
-   ‚úÖ Validar cada fase antes de continuar
-   ‚úÖ Mantener compatibilidad con datos existentes

## üèóÔ∏è Arquitectura Comparativa

### MVP Architecture

```mermaid
graph LR
    WA[WhatsApp Webhook] --> N8N_Basic[N8N (Basic)]
    N8N_Basic --> PG_Simple[PostgreSQL (Simple)]
    WA --> StockAPI[Stock Mgmt API]
```

### Sistema Completo Architecture

```mermaid
graph TD
    WA[WhatsApp Webhook] --> N8N_Queue[N8N Queue (Workers)]
    N8N_Queue --> Redis[Redis (Cache)]
    N8N_Queue --> PG_Optimized[PostgreSQL (Optimized)]
    WA --> AI_Providers[AI Providers (Multiple)]
```

## üìä Funcionalidades y Migraci√≥n

### 1. **Parseo de Mensajes**

| Aspecto            | MVP               | Sistema Completo        | Impacto   |
| ------------------ | ----------------- | ----------------------- | --------- |
| **Tipos soportados** | text, interactive | Todos + multimedia      | üü¢ Bajo   |
| **Validaci√≥n**     | B√°sica            | Avanzada con hash       | üü° Medio  |
| **Performance**    | ~50ms             | ~20ms                   | üü¢ Bajo   |

**Nodos a migrar:**

-   Reemplazar: `parse_message_mvp`
-   Por: `parse_message_optimized`

**Consideraciones:**

-   Retrocompatible con mensajes existentes
-   No requiere cambios en BD
-   Mejora autom√°tica de performance

### 2. **Rate Limiting**

| Aspecto          | MVP           | Sistema Completo     | Impacto   |
| ---------------- | ------------- | -------------------- | --------- |
| **Implementaci√≥n** | No incluido   | In-memory + DB       | üî¥ Alto   |
| **L√≠mites**      | N/A           | 5 msg/min, 100/hora  | üü° Medio  |
| **Storage**      | N/A           | Redis + PostgreSQL   | üî¥ Alto   |

**Nodos a agregar:**

-   `optimized_rate_limiter` despu√©s de parseo
-   `filter_skip_processing` para manejar l√≠mites

**Consideraciones:**

-   Requiere Redis operativo
-   Configurar l√≠mites seg√∫n plan de usuario
-   Implementar notificaciones de l√≠mite alcanzado

### 3. **Sistema de Sesiones**

| Aspecto       | MVP              | Sistema Completo     | Impacto   |
| ------------- | ---------------- | -------------------- | --------- |
| **Storage**   | PostgreSQL only  | Redis + PostgreSQL   | üî¥ Alto   |
| **TTL**       | 2 horas fijo     | Configurable         | üü¢ Bajo   |
| **Performance** | ~100ms           | ~10ms                | üü° Medio  |

**Nodos a migrar:**

-   Reemplazar: `get_session_mvp`
-   Por: `redis_cache_manager_consolidated`

**Script de migraci√≥n de sesiones:**

```sql
-- Migrar sesiones existentes a formato optimizado
UPDATE customer_sessions
SET
  context_data = jsonb_set(
    COALESCE(context_data, '{}'::jsonb),
    '{migrated_from_mvp}',
    'true'
  ),
  updated_at = NOW()
WHERE context_data IS NULL
   OR NOT (context_data ? 'session_version');
```

### 4. **Detecci√≥n de Intenciones**

| Aspecto   | MVP            | Sistema Completo    | Impacto      |
|-----------|----------------|---------------------|--------------|
| M√©todo    | Palabras clave | AI Multi-provider   | üî¥ Alto      |
| Precisi√≥n | ~70%           | ~95%                | üü¢ Positivo  |
| Latencia  | <10ms          | 50-300ms            | üü° Medio     |
| Costo     | $0             | $0.001-0.01/req     | üî¥ Alto      |

**Nodos a migrar:**

-   Reemplazar: `intent_detection_mvp`
-   Por: `ai_provider_ultra_optimized`

**Configuraci√≥n requerida:**

```javascript
// Providers configuration
const AI_PROVIDERS = {
  deepseek: { enabled: true, apiKey: process.env.DEEPSEEK_API_KEY },
  gemini: { enabled: true, apiKey: process.env.GEMINI_API_KEY },
  openai: { enabled: false, apiKey: process.env.OPENAI_API_KEY }
};
```

### 5. **Gesti√≥n de Categor√≠as**

| Aspecto  | MVP    | Sistema Completo      | Impacto   |
|----------|--------|-----------------------|-----------|
| Cache    | No     | Redis 30 min          | üü° Medio  |
| Query    | Simple | Optimizada con MV     | üü¢ Bajo   |
| Features | B√°sicas| Destacados, ofertas   | üü¢ Bajo   |

**Nodos a agregar:**

-   `optimized_category_cache` antes de DB query
-   Actualizar query para usar vista materializada

### 6. **B√∫squeda de Productos**

| Aspecto     | MVP         | Sistema Completo        | Impacto     |
|-------------|-------------|-------------------------|-------------|
| M√©todo      | LIKE simple | Full-text + scoring     | üü° Medio    |
| Performance | ~200ms      | ~50ms                   | üü¢ Positivo |
| Relevancia  | B√°sica      | Avanzada con ML         | üü¢ Positivo |

**Nodos a migrar:**

-   Reemplazar: `search_products_mvp`
-   Por: `ultra_optimized_product_search`

**√çndices requeridos:**

```sql
-- Crear √≠ndices para b√∫squeda optimizada
CREATE INDEX CONCURRENTLY idx_products_search_vector
ON products USING GIN(to_tsvector('spanish', name || ' ' || COALESCE(description, '')));

CREATE INDEX CONCURRENTLY idx_products_popularity
ON products(popularity_score DESC)
WHERE is_available = true;
```

### 7. **Gesti√≥n de Carrito**

| Aspecto    | MVP          | Sistema Completo     | Impacto   |
|------------|--------------|----------------------|-----------|
| Storage    | Session JSON | Redis + validaci√≥n   | üî¥ Alto   |
| Validaci√≥n | M√≠nima       | Stock real-time      | üü° Medio  |
| Features   | Add/View     | CRUD completo        | üü° Medio  |

**Nodos a agregar:**

-   Flow 5 completo para gesti√≥n avanzada
-   Validaci√≥n de stock en tiempo real
-   C√°lculo de env√≠o y descuentos

### 8. **Proceso de Checkout**

| Aspecto      | MVP | Sistema Completo                | Impacto   |
|--------------|-----|---------------------------------|-----------|
| Incluido     | No  | S√≠, completo                    | üî¥ Alto   |
| Pasos        | N/A | Direcci√≥n, pago, confirmaci√≥n   | üî¥ Alto   |
| Integraciones| N/A | Pasarelas de pago               | üî¥ Alto   |

**Nodos a implementar:**

-   `optimized_checkout_processor`
-   Integraci√≥n con pasarelas de pago
-   Validaci√≥n de direcci√≥n
-   Generaci√≥n de orden

### 9. **Sistema de M√©tricas**

| Aspecto   | MVP | Sistema Completo    | Impacto   |
|-----------|-----|---------------------|-----------|
| Eventos   | No  | Event sourcing      | üü° Medio  |
| Analytics | No  | Real-time           | üü° Medio  |
| Reportes  | No  | Dashboard completo  | üü¢ Bajo   |

**Nodos a agregar:**

-   `lightweight_metrics` en cada flujo
-   `record_intent_event` para analytics
-   Integraci√≥n con sistema de reportes

## üîÑ Proceso de Migraci√≥n

### Fase 1: Preparaci√≥n (1-2 d√≠as)

-   Backup completo de datos actuales
-   Configurar Redis en ambiente de producci√≥n
-   Crear √≠ndices requeridos en PostgreSQL
-   Configurar API keys para AI providers
-   Setup monitoring para nueva arquitectura

### Fase 2: Migraci√≥n de Infraestructura (2-3 d√≠as)

-   Deploy Redis cluster
-   Actualizar PostgreSQL con nuevas tablas/vistas
-   Configurar N8N en modo queue
-   Setup workers para procesamiento paralelo

### Fase 3: Migraci√≥n de Flujos (5-7 d√≠as)

-   **D√≠a 1-2**: Parseo y Rate Limiting
-   **D√≠a 3**: Sistema de Sesiones
-   **D√≠a 4**: AI Integration
-   **D√≠a 5**: B√∫squeda y Categor√≠as
-   **D√≠a 6-7**: Carrito y Checkout

### Fase 4: Testing y Validaci√≥n (2-3 d√≠as)

-   Testing funcional de cada componente
-   Pruebas de carga con tr√°fico simulado
-   Validaci√≥n de m√©tricas
-   User Acceptance Testing

### Fase 5: Go Live (1 d√≠a)

-   Migraci√≥n gradual del tr√°fico
-   Monitoreo intensivo
-   Rollback plan activo
-   Comunicaci√≥n a usuarios

## ‚úÖ Validaci√≥n y Testing

### Checklist de Validaci√≥n por Componente

-   **Parseo de Mensajes**
    -   ‚úì Mensajes de texto procesados correctamente
    -   ‚úì Mensajes interactivos funcionando
    -   ‚úì Multimedia manejado sin errores
    -   ‚úì Hashes √∫nicos generados
-   **Rate Limiting**
    -   ‚úì L√≠mites aplicados correctamente
    -   ‚úì Mensajes de l√≠mite alcanzado
    -   ‚úì Reset de contadores funcionando
    -   ‚úì Logs de rate limit activos
-   **Sesiones**
    -   ‚úì Migraci√≥n de sesiones existentes
    -   ‚úì Cache hit rate > 80%
    -   ‚úì TTL funcionando correctamente
    -   ‚úì Sincronizaci√≥n Redis-PostgreSQL
-   **AI Integration**
    -   ‚úì Fallback a keywords si AI falla
    -   ‚úì Circuit breaker activo
    -   ‚úì Latencia < 500ms p95
    -   ‚úì Precisi√≥n > 90%

## üîÑ Rollback Strategy

### Plan de Rollback por Fase

-   **Rollback Inmediato (< 5 min)**
    -   Switch de tr√°fico a flujo MVP
    -   Mantener datos en ambos sistemas
    -   Alertas autom√°ticas activas
-   **Rollback Parcial (< 30 min)**
    -   Desactivar componentes problem√°ticos
    -   Fallback a implementaci√≥n MVP
    -   Mantener features no afectadas
-   **Rollback Completo (< 2 horas)**
    -   Restore de backup pre-migraci√≥n
    -   Revertir cambios de infraestructura
    -   Comunicaci√≥n a usuarios afectados

### Comandos de Rollback

```bash
# Rollback inmediato - Switch de tr√°fico
n8n workflow:deactivate "Sistema Completo"
n8n workflow:activate "MVP WhatsApp Commerce"

# Rollback de sesiones a PostgreSQL only
redis-cli FLUSHDB
UPDATE system_config SET value = 'false' WHERE key = 'use_redis_sessions';

# Rollback de AI a keywords
UPDATE system_config SET value = 'false' WHERE key = 'use_ai_providers';
```

## üìà M√©tricas de √âxito

| M√©trica                   | Target   | Cr√≠tico |
|---------------------------|----------|---------|
| Uptime durante migraci√≥n  | > 99.9%  | < 99%   |
| Latencia p95              | < 500ms  | > 1000ms|
| Error rate                | < 0.1%   | > 1%    |
| AI accuracy               | > 90%    | < 80%   |
| Cache hit rate            | > 80%    | < 60%   |
| User satisfaction         | > 4.5/5  | < 4.0/5 |

## üö® Contactos de Emergencia

-   Technical Lead: `[contacto]`
-   DevOps On-Call: `[contacto]`
-   Business Owner: `[contacto]`
-   Escalation Path: L1 ‚Üí L2 ‚Üí L3 ‚Üí Management

---

## üõ†Ô∏è Scripts de Migraci√≥n: MVP a Sistema Completo

### üìã √çndice de Scripts

1.  [Pre-migraci√≥n: Validaci√≥n y Backup](#1-pre-migraci√≥n-validaci√≥n-y-backup)
2.  [Migraci√≥n de Sesiones](#2-migraci√≥n-de-sesiones)
3.  [Migraci√≥n de Rate Limiting](#3-migraci√≥n-de-rate-limiting)
4.  [Configuraci√≥n de AI Providers](#4-configuraci√≥n-de-ai-providers)
5.  [Optimizaci√≥n de B√∫squedas](#5-optimizaci√≥n-de-b√∫squedas)
6.  [Migraci√≥n de Carrito](#6-migraci√≥n-de-carrito)
7.  [Post-migraci√≥n: Validaci√≥n](#7-post-migraci√≥n-validaci√≥n)

### 1. Pre-migraci√≥n: Validaci√≥n y Backup

#### validate-pre-migration.js

```javascript
/**
 * Script de validaci√≥n pre-migraci√≥n
 * Verifica que el sistema est√© listo para migrar
 */

const { Pool } = require('pg');
const Redis = require('redis');
const axios = require('axios');

const CONFIG = {
  postgres: {
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD
  },
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: process.env.REDIS_PORT || 6379
  },
  ai_providers: {
    deepseek: process.env.DEEPSEEK_API_KEY,
    gemini: process.env.GEMINI_API_KEY
  }
};

async function validatePreMigration() {
  console.log('üîç Iniciando validaci√≥n pre-migraci√≥n...\n');

  const results = {
    postgres: false,
    redis: false,
    ai_providers: false,
    backup: false,
    indices: false
  };

  // 1. Validar PostgreSQL
  try {
    const pool = new Pool(CONFIG.postgres);
    const res = await pool.query('SELECT NOW()');
    console.log('‚úÖ PostgreSQL: Conectado');

    // Verificar tablas requeridas
    const tables = ['customer_sessions', 'products', 'categories', 'message_logs'];
    for (const table of tables) {
      const tableExists = await pool.query(
        "SELECT EXISTS (SELECT FROM pg_tables WHERE tablename = $1)",
        [table]
      );
      if (!tableExists.rows[0].exists) {
        throw new Error(`Tabla ${table} no existe`);
      }
    }
    console.log('‚úÖ PostgreSQL: Todas las tablas existen');
    results.postgres = true;
    await pool.end();
  } catch (error) {
    console.error('‚ùå PostgreSQL:', error.message);
  }

  // 2. Validar Redis
  try {
    const client = Redis.createClient(CONFIG.redis);
    await client.connect();
    await client.ping();
    console.log('‚úÖ Redis: Conectado y funcionando');
    results.redis = true;
    await client.quit();
  } catch (error) {
    console.error('‚ùå Redis:', error.message);
  }

  // 3. Validar AI Providers
  try {
    let validProviders = 0;

    if (CONFIG.ai_providers.deepseek) {
      // Validar Deepseek API
      console.log('‚úÖ Deepseek API key configurada');
      validProviders++;
    }

    if (CONFIG.ai_providers.gemini) {
      // Validar Gemini API
      console.log('‚úÖ Gemini API key configurada');
      validProviders++;
    }

    if (validProviders === 0) {
      throw new Error('No hay AI providers configurados');
    }

    results.ai_providers = true;
  } catch (error) {
    console.error('‚ùå AI Providers:', error.message);
  }

  // 4. Crear backup
  try {
    console.log('\nüì¶ Creando backup de datos...');
    const pool = new Pool(CONFIG.postgres);

    // Backup de sesiones activas
    const sessions = await pool.query(
      'SELECT * FROM customer_sessions WHERE expires_at > NOW()'
    );

    const fs = require('fs');
    const backupDir = './backups';
    if (!fs.existsSync(backupDir)) {
      fs.mkdirSync(backupDir);
    }

    const backupFile = `${backupDir}/pre_migration_${Date.now()}.json`;
    fs.writeFileSync(backupFile, JSON.stringify({
      timestamp: new Date().toISOString(),
      sessions: sessions.rows,
      session_count: sessions.rows.length
    }, null, 2));

    console.log(`‚úÖ Backup creado: ${backupFile}`);
    results.backup = true;
    await pool.end();
  } catch (error) {
    console.error('‚ùå Backup:', error.message);
  }

  // Resumen
  console.log('\nüìä Resumen de Validaci√≥n:');
  console.log('------------------------');
  Object.entries(results).forEach(([key, value]) => {
    console.log(`${key}: ${value ? '‚úÖ' : '‚ùå'}`);
  });

  const allPassed = Object.values(results).every(v => v);
  if (allPassed) {
    console.log('\nüéâ Sistema listo para migraci√≥n!');
    process.exit(0);
  } else {
    console.log('\n‚ùå Sistema NO est√° listo para migraci√≥n. Corrige los errores antes de continuar.');
    process.exit(1);
  }
}

validatePreMigration();
```

### 2. Migraci√≥n de Sesiones

#### migrate-sessions.js

```javascript
/**
 * Migraci√≥n de sesiones de PostgreSQL a Redis
 * Mantiene compatibilidad con sistema MVP
 */

const { Pool } = require('pg');
const Redis = require('redis');

async function migrateSessions() {
  console.log('üîÑ Iniciando migraci√≥n de sesiones...\n');

  const pgPool = new Pool({
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD
  });

  const redisClient = Redis.createClient({
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT
  });

  try {
    await redisClient.connect();

    // 1. Obtener todas las sesiones activas
    const sessions = await pgPool.query(`
      SELECT
        cs.*,
        c.name as customer_name,
        c.total_orders,
        c.customer_tier
      FROM customer_sessions cs
      LEFT JOIN customers c ON cs.customer_phone = c.phone
      WHERE cs.expires_at > NOW()
    `);

    console.log(`üìä Encontradas ${sessions.rows.length} sesiones activas\n`);

    // 2. Migrar cada sesi√≥n a Redis
    let migrated = 0;
    let failed = 0;

    for (const session of sessions.rows) {
      try {
        const sessionKey = `session:${session.customer_phone}`;
        const ttl = Math.floor((new Date(session.expires_at) - new Date()) / 1000);

        const sessionData = {
          id: session.id,
          customer_phone: session.customer_phone,
          customer_name: session.customer_name || 'Cliente',
          session_state: session.session_state,
          cart_data: session.cart_data || [],
          context_data: session.context_data || {},
          total_orders: session.total_orders || 0,
          customer_tier: session.customer_tier || 'new',
          last_activity: session.updated_at,
          migrated_at: new Date().toISOString(),
          version: 'v2'
        };

        await redisClient.setEx(
          sessionKey,
          ttl > 0 ? ttl : 7200, // Default 2 horas
          JSON.stringify(sessionData)
        );

        // Marcar como migrada en PostgreSQL
        await pgPool.query(`
          UPDATE customer_sessions
          SET context_data = jsonb_set(
            COALESCE(context_data, '{}'::jsonb),
            '{migrated_to_redis}',
            'true'
          )
          WHERE id = $1
        `, [session.id]);

        migrated++;
        console.log(`‚úÖ Migrada sesi√≥n para ${session.customer_phone}`);
      } catch (error) {
        failed++;
        console.error(`‚ùå Error migrando sesi√≥n ${session.id}:`, error.message);
      }
    }

    console.log('\nüìä Resumen de Migraci√≥n:');
    console.log(`Total: ${sessions.rows.length}`);
    console.log(`Migradas: ${migrated}`);
    console.log(`Fallidas: ${failed}`);

    // 3. Verificar migraci√≥n
    const keysInRedis = await redisClient.keys('session:*');
    console.log(`\n‚úÖ Sesiones en Redis: ${keysInRedis.length}`);

  } catch (error) {
    console.error('‚ùå Error fatal:', error);
    process.exit(1);
  } finally {
    await pgPool.end();
    await redisClient.quit();
  }
}

migrateSessions();
```

### 3. Migraci√≥n de Rate Limiting

#### setup-rate-limiting.js

```javascript
/**
 * Configuraci√≥n del sistema de rate limiting
 * Crea estructuras necesarias en Redis y PostgreSQL
 */

const { Pool } = require('pg');
const Redis = require('redis');

async function setupRateLimiting() {
  console.log('üö¶ Configurando Rate Limiting...\n');

  const pgPool = new Pool({
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD
  });

  const redisClient = Redis.createClient({
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT
  });

  try {
    await redisClient.connect();

    // 1. Crear tabla de configuraci√≥n de rate limits si no existe
    await pgPool.query(`
      CREATE TABLE IF NOT EXISTS rate_limit_config (
        id SERIAL PRIMARY KEY,
        customer_tier VARCHAR(50) NOT NULL UNIQUE,
        max_per_minute INTEGER NOT NULL,
        max_per_hour INTEGER NOT NULL,
        max_per_day INTEGER NOT NULL,
        burst_size INTEGER NOT NULL,
        created_at TIMESTAMP DEFAULT NOW(),
        updated_at TIMESTAMP DEFAULT NOW()
      )
    `);

    // 2. Insertar configuraci√≥n por defecto
    await pgPool.query(`
      INSERT INTO rate_limit_config (customer_tier, max_per_minute, max_per_hour, max_per_day, burst_size)
      VALUES
        ('new', 5, 60, 500, 10),
        ('regular', 10, 120, 1000, 20),
        ('vip', 20, 300, 2000, 50)
      ON CONFLICT (customer_tier) DO UPDATE
      SET updated_at = NOW()
    `);

    console.log('‚úÖ Configuraci√≥n de rate limits creada en PostgreSQL');

    // 3. Crear estructura de rate limiting en Redis
    const rateLimitScript = `
      local key = KEYS[1]
      local window = ARGV[1]
      local limit = tonumber(ARGV[2])
      local now = tonumber(ARGV[3])
      local clearBefore = now - window

      redis.call('zremrangebyscore', key, 0, clearBefore)
      local current = redis.call('zcard', key)

      if current < limit then
        redis.call('zadd', key, now, now)
        redis.call('expire', key, window)
        return {1, limit - current - 1}
      else
        return {0, 0}
      end
    `;

    // Registrar script en Redis
    const scriptSha = await redisClient.scriptLoad(rateLimitScript);

    // Guardar SHA del script
    await redisClient.set('rate_limit_script_sha', scriptSha);

    console.log('‚úÖ Script de rate limiting registrado en Redis');

    // 4. Crear √≠ndices para message_logs
    await pgPool.query(`
      CREATE INDEX IF NOT EXISTS idx_message_logs_rate_limit
      ON message_logs(customer_phone, message_timestamp DESC)
      WHERE rate_limit_exceeded = false
    `);

    console.log('‚úÖ √çndices optimizados creados');

    // 5. Test del rate limiting
    console.log('\nüß™ Testeando rate limiting...');

    const testPhone = '1234567890';
    const testKey = `rate_limit:${testPhone}:minute`;

    // Simular 5 requests
    for (let i = 0; i < 5; i++) {
      const now = Date.now();
      const result = await redisClient.evalSha(
        scriptSha,
        {
          keys: [testKey],
          arguments: ['60', '5', now.toString()]
        }
      );
      console.log(`Request ${i + 1}: ${result[0] === 1 ? 'Permitido' : 'Bloqueado'}`);
    }

    // Limpiar test
    await redisClient.del(testKey);

    console.log('\n‚úÖ Rate limiting configurado exitosamente!');

  } catch (error) {
    console.error('‚ùå Error:', error);
    process.exit(1);
  } finally {
    await pgPool.end();
    await redisClient.quit();
  }
}

setupRateLimiting();
```

### 4. Configuraci√≥n de AI Providers

#### setup-ai-providers.js

```javascript
/**
 * Configuraci√≥n y testing de AI providers
 * Configura circuit breakers y fallbacks
 */

const axios = require('axios');
const { Pool } = require('pg');
const Redis = require('redis');

const AI_PROVIDERS = {
  deepseek: {
    name: 'DeepSeek',
    endpoint: 'https://api.deepseek.com/v1/chat/completions',
    model: 'deepseek-chat',
    apiKey: process.env.DEEPSEEK_API_KEY,
    cost: 0.00014,
    timeout: 5000
  },
  gemini: {
    name: 'Gemini',
    endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent',
    apiKey: process.env.GEMINI_API_KEY,
    cost: 0.000075,
    timeout: 3000
  }
};

async function setupAIProviders() {
  console.log('ü§ñ Configurando AI Providers...\n');

  const pgPool = new Pool({
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD
  });

  const redisClient = Redis.createClient({
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT
  });

  try {
    await redisClient.connect();

    // 1. Crear tabla de configuraci√≥n de AI
    await pgPool.query(`
      CREATE TABLE IF NOT EXISTS ai_provider_config (
        id SERIAL PRIMARY KEY,
        provider_name VARCHAR(50) UNIQUE NOT NULL,
        is_enabled BOOLEAN DEFAULT true,
        priority INTEGER DEFAULT 100,
        max_tokens INTEGER DEFAULT 150,
        temperature DECIMAL(3,2) DEFAULT 0.7,
        cost_per_request DECIMAL(10,6),
        timeout_ms INTEGER DEFAULT 5000,
        circuit_breaker_threshold INTEGER DEFAULT 5,
        circuit_breaker_timeout INTEGER DEFAULT 300, -- seconds
        created_at TIMESTAMP DEFAULT NOW(),
        updated_at TIMESTAMP DEFAULT NOW()
      )
    `);

    // 2. Insertar configuraci√≥n de providers
    for (const [key, provider] of Object.entries(AI_PROVIDERS)) {
      await pgPool.query(`
        INSERT INTO ai_provider_config
        (provider_name, cost_per_request, timeout_ms, priority)
        VALUES ($1, $2, $3, $4)
        ON CONFLICT (provider_name)
        DO UPDATE SET
          cost_per_request = EXCLUDED.cost_per_request,
          timeout_ms = EXCLUDED.timeout_ms,
          priority = EXCLUDED.priority,
          updated_at = NOW()
      `, [provider.name, provider.cost, provider.timeout, key === 'gemini' ? 90 : 100]); // Gemini higher priority (lower number)
    }
    console.log('‚úÖ Configuraci√≥n de AI providers insertada/actualizada en PostgreSQL');

    // 3. Testear cada provider (ejemplo b√°sico)
    for (const [key, provider] of Object.entries(AI_PROVIDERS)) {
      if (!provider.apiKey) {
        console.warn(`‚ö†Ô∏è API Key para ${provider.name} no configurada. Saltando test.`);
        continue;
      }

      console.log(`\nüß™ Testeando ${provider.name}...`);
      try {
        let response;
        if (provider.name === 'DeepSeek') {
          response = await axios.post(provider.endpoint, {
            model: provider.model,
            messages: [{ role: 'user', content: 'Hola' }],
            max_tokens: 10,
          }, {
            headers: { Authorization: `Bearer ${provider.apiKey}` },
            timeout: provider.timeout
          });
        } else if (provider.name === 'Gemini') {
          response = await axios.post(`${provider.endpoint}?key=${provider.apiKey}`, {
            contents: [{ parts: [{ text: "Hola" }] }]
          }, { timeout: provider.timeout });
        }

        if (response && response.status === 200) {
          console.log(`‚úÖ ${provider.name}: Conexi√≥n exitosa.`);
          // Guardar estado en Redis (ej. circuit breaker)
          await redisClient.set(`ai_provider:${key}:status`, 'ok');
          await redisClient.del(`ai_provider:${key}:failures`);
        } else {
          throw new Error(`Status ${response ? response.status : 'unknown'}`);
        }
      } catch (error) {
        console.error(`‚ùå ${provider.name}: Error - ${error.message}`);
        // Incrementar contador de fallos para circuit breaker
        const failures = await redisClient.incr(`ai_provider:${key}:failures`);
        await redisClient.expire(`ai_provider:${key}:failures`, 3600); // Expira en 1 hora
        console.warn(`üî• ${provider.name}: Fallos consecutivos: ${failures}`);
      }
    }

    console.log('\n‚úÖ Configuraci√≥n y testing b√°sico de AI Providers completado!');

  } catch (error) {
    console.error('‚ùå Error fatal en configuraci√≥n de AI:', error);
    process.exit(1);
  } finally {
    await pgPool.end();
    await redisClient.quit();
  }
}

setupAIProviders();
```
